<!doctype html><html lang=en dir=auto data-theme=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>CUDA 的系统组成-面向他人讲解 | LouFY'Log</title><meta name=keywords content><meta name=description content="很棒的资料

https://jamesakl.com/posts/cuda-ontology/ 详细系统讲解了CUDA整体

从顶往下：GPU 软件栈的层次结构
可以把 CUDA 系统理解成从硬件到应用的四层结构：
┌──────────────────────────┐
│ 你的深度学习程序 (PyTorch / TensorFlow) │ ← 应用层
├──────────────────────────┤
│ CUDA Toolkit / cuDNN / cuBLAS / 驱动API │ ← 开发与加速库层
├──────────────────────────┤
│ NVIDIA 驱动 (Driver) │ ← 驱动层
├──────────────────────────┤
│ GPU 硬件 (2080 Ti 等) │ ← 硬件层
└──────────────────────────┘
“我的 Python 程序通过 PyTorch 调用 CUDA Runtime API，
CUDA Runtime 依赖 NVIDIA 驱动与硬件通信，
驱动再控制显卡完成底层计算。”
“CUDA 生态是一整套 GPU 加速栈：
从最底层的硬件到驱动，再到 Toolkit 和加速库，最后被深度学习框架调用。
驱动连接硬件，Toolkit 提供编译和库接口，
框架调用这些接口完成并行计算。”"><meta name=author content="Lou Feiyu"><link rel=canonical href=http://localhost:1313/posts/code_trail-cuda-%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90-%E9%9D%A2%E5%90%91%E4%BB%96%E4%BA%BA%E8%AE%B2%E8%A7%A3/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/code_trail-cuda-%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90-%E9%9D%A2%E5%90%91%E4%BB%96%E4%BA%BA%E8%AE%B2%E8%A7%A3/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="http://localhost:1313/posts/code_trail-cuda-%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90-%E9%9D%A2%E5%90%91%E4%BB%96%E4%BA%BA%E8%AE%B2%E8%A7%A3/"><meta property="og:site_name" content="LouFY'Log"><meta property="og:title" content="CUDA 的系统组成-面向他人讲解"><meta property="og:description" content="很棒的资料 https://jamesakl.com/posts/cuda-ontology/ 详细系统讲解了CUDA整体 从顶往下：GPU 软件栈的层次结构 可以把 CUDA 系统理解成从硬件到应用的四层结构：
┌──────────────────────────┐ │ 你的深度学习程序 (PyTorch / TensorFlow) │ ← 应用层 ├──────────────────────────┤ │ CUDA Toolkit / cuDNN / cuBLAS / 驱动API │ ← 开发与加速库层 ├──────────────────────────┤ │ NVIDIA 驱动 (Driver) │ ← 驱动层 ├──────────────────────────┤ │ GPU 硬件 (2080 Ti 等) │ ← 硬件层 └──────────────────────────┘ “我的 Python 程序通过 PyTorch 调用 CUDA Runtime API， CUDA Runtime 依赖 NVIDIA 驱动与硬件通信， 驱动再控制显卡完成底层计算。”
“CUDA 生态是一整套 GPU 加速栈： 从最底层的硬件到驱动，再到 Toolkit 和加速库，最后被深度学习框架调用。 驱动连接硬件，Toolkit 提供编译和库接口， 框架调用这些接口完成并行计算。”"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-01T00:00:00+00:00"><meta property="article:modified_time" content="2025-11-01T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="CUDA 的系统组成-面向他人讲解"><meta name=twitter:description content="很棒的资料

https://jamesakl.com/posts/cuda-ontology/ 详细系统讲解了CUDA整体

从顶往下：GPU 软件栈的层次结构
可以把 CUDA 系统理解成从硬件到应用的四层结构：
┌──────────────────────────┐
│ 你的深度学习程序 (PyTorch / TensorFlow) │ ← 应用层
├──────────────────────────┤
│ CUDA Toolkit / cuDNN / cuBLAS / 驱动API │ ← 开发与加速库层
├──────────────────────────┤
│ NVIDIA 驱动 (Driver) │ ← 驱动层
├──────────────────────────┤
│ GPU 硬件 (2080 Ti 等) │ ← 硬件层
└──────────────────────────┘
“我的 Python 程序通过 PyTorch 调用 CUDA Runtime API，
CUDA Runtime 依赖 NVIDIA 驱动与硬件通信，
驱动再控制显卡完成底层计算。”
“CUDA 生态是一整套 GPU 加速栈：
从最底层的硬件到驱动，再到 Toolkit 和加速库，最后被深度学习框架调用。
驱动连接硬件，Toolkit 提供编译和库接口，
框架调用这些接口完成并行计算。”"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"CUDA 的系统组成-面向他人讲解","item":"http://localhost:1313/posts/code_trail-cuda-%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90-%E9%9D%A2%E5%90%91%E4%BB%96%E4%BA%BA%E8%AE%B2%E8%A7%A3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"CUDA 的系统组成-面向他人讲解","name":"CUDA 的系统组成-面向他人讲解","description":"很棒的资料 https://jamesakl.com/posts/cuda-ontology/ 详细系统讲解了CUDA整体 从顶往下：GPU 软件栈的层次结构 可以把 CUDA 系统理解成从硬件到应用的四层结构：\n┌──────────────────────────┐ │ 你的深度学习程序 (PyTorch / TensorFlow) │ ← 应用层 ├──────────────────────────┤ │ CUDA Toolkit / cuDNN / cuBLAS / 驱动API │ ← 开发与加速库层 ├──────────────────────────┤ │ NVIDIA 驱动 (Driver) │ ← 驱动层 ├──────────────────────────┤ │ GPU 硬件 (2080 Ti 等) │ ← 硬件层 └──────────────────────────┘ “我的 Python 程序通过 PyTorch 调用 CUDA Runtime API， CUDA Runtime 依赖 NVIDIA 驱动与硬件通信， 驱动再控制显卡完成底层计算。”\n“CUDA 生态是一整套 GPU 加速栈： 从最底层的硬件到驱动，再到 Toolkit 和加速库，最后被深度学习框架调用。 驱动连接硬件，Toolkit 提供编译和库接口， 框架调用这些接口完成并行计算。”\n","keywords":[null],"articleBody":"很棒的资料 https://jamesakl.com/posts/cuda-ontology/ 详细系统讲解了CUDA整体 从顶往下：GPU 软件栈的层次结构 可以把 CUDA 系统理解成从硬件到应用的四层结构：\n┌──────────────────────────┐ │ 你的深度学习程序 (PyTorch / TensorFlow) │ ← 应用层 ├──────────────────────────┤ │ CUDA Toolkit / cuDNN / cuBLAS / 驱动API │ ← 开发与加速库层 ├──────────────────────────┤ │ NVIDIA 驱动 (Driver) │ ← 驱动层 ├──────────────────────────┤ │ GPU 硬件 (2080 Ti 等) │ ← 硬件层 └──────────────────────────┘ “我的 Python 程序通过 PyTorch 调用 CUDA Runtime API， CUDA Runtime 依赖 NVIDIA 驱动与硬件通信， 驱动再控制显卡完成底层计算。”\n“CUDA 生态是一整套 GPU 加速栈： 从最底层的硬件到驱动，再到 Toolkit 和加速库，最后被深度学习框架调用。 驱动连接硬件，Toolkit 提供编译和库接口， 框架调用这些接口完成并行计算。”\n层级 名称 作用 举例或说明 硬件层 GPU 芯片 负责并行计算（核心算力来源） RTX 2080 Ti, RTX 3070, A100 驱动层 NVIDIA Driver 操作系统和 GPU 之间的桥梁，负责调度 GPU 资源 比如 Driver Version: 535.230.02 运行库层 CUDA Runtime / cuDNN / cuBLAS / cuFFT 等 NVIDIA 提供的各种 GPU 加速库 PyTorch 调用 cuDNN 做卷积、cuBLAS 做矩阵乘 工具包层 CUDA Toolkit 包含编译器 nvcc、头文件、开发工具 CUDA 11.3, 12.1 等 应用层 深度学习框架 / 程序 你的 Python 代码、PyTorch、TensorFlow 等 torch.cuda.is_available() 驱动必须 ≥ CUDA Toolkit 要求的最低版本。驱动新版可以兼容老 CUDA。\n当用 conda install pytorch cudatoolkit=11.3 时，这套 CUDA runtime 是内置在 PyTorch 包里的，不会依赖系统路径\n所以哪怕系统没装 /usr/local/cuda，PyTorch 依然能跑。 torch.version.cuda 看到的版本即 PyTorch 编译时自带的 CUDA 版本。 排查命令\n检查命令 作用 nvidia-smi 驱动+GPU检测 nvcc -V CUDA Toolkit 版本（如果系统安装了） python -c “import torch; print(torch.version.cuda)” PyTorch 自带 CUDA 版本 torch.cuda.is_available() 是否能用 GPU ","wordCount":"184","inLanguage":"en","datePublished":"2025-11-01T00:00:00Z","dateModified":"2025-11-01T00:00:00Z","author":{"@type":"Person","name":"Lou Feiyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/code_trail-cuda-%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90-%E9%9D%A2%E5%90%91%E4%BB%96%E4%BA%BA%E8%AE%B2%E8%A7%A3/"},"publisher":{"@type":"Organization","name":"LouFY'Log","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="LouFY'Log (Alt + H)">LouFY'Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/posts/ title=Posts><span>Posts</span></a></li><li><a href=http://localhost:1313/archives/ title=Archive><span>Archive</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=http://localhost:1313/faq/ title=FAQ><span>FAQ</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">CUDA 的系统组成-面向他人讲解</h1><div class=post-meta><span title='2025-11-01 00:00:00 +0000 UTC'>2025-11-01</span>&nbsp;·&nbsp;<span>1 min</span>&nbsp;·&nbsp;<span>184 words</span>&nbsp;·&nbsp;<span>Lou Feiyu</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%be%88%e6%a3%92%e7%9a%84%e8%b5%84%e6%96%99 aria-label=很棒的资料>很棒的资料</a></li><li><a href=#%e4%bb%8e%e9%a1%b6%e5%be%80%e4%b8%8bgpu-%e8%bd%af%e4%bb%b6%e6%a0%88%e7%9a%84%e5%b1%82%e6%ac%a1%e7%bb%93%e6%9e%84 aria-label="从顶往下：GPU 软件栈的层次结构">从顶往下：GPU 软件栈的层次结构</a></li></ul></div></details></div><div class=post-content><h2 id=很棒的资料>很棒的资料<a hidden class=anchor aria-hidden=true href=#很棒的资料>#</a></h2><ol><li><a href=https://jamesakl.com/posts/cuda-ontology/>https://jamesakl.com/posts/cuda-ontology/</a> 详细系统讲解了CUDA整体</li></ol><h2 id=从顶往下gpu-软件栈的层次结构>从顶往下：GPU 软件栈的层次结构<a hidden class=anchor aria-hidden=true href=#从顶往下gpu-软件栈的层次结构>#</a></h2><p>可以把 CUDA 系统理解成<strong>从硬件到应用的四层结构</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>┌──────────────────────────┐
</span></span><span style=display:flex><span>│ 你的深度学习程序 <span style=color:#f92672>(</span>PyTorch / TensorFlow<span style=color:#f92672>)</span> │ ← 应用层
</span></span><span style=display:flex><span>├──────────────────────────┤
</span></span><span style=display:flex><span>│ CUDA Toolkit / cuDNN / cuBLAS / 驱动API │ ← 开发与加速库层
</span></span><span style=display:flex><span>├──────────────────────────┤
</span></span><span style=display:flex><span>│ NVIDIA 驱动 <span style=color:#f92672>(</span>Driver<span style=color:#f92672>)</span> │ ← 驱动层
</span></span><span style=display:flex><span>├──────────────────────────┤
</span></span><span style=display:flex><span>│ GPU 硬件 <span style=color:#f92672>(</span><span style=color:#ae81ff>2080</span> Ti 等<span style=color:#f92672>)</span> │ ← 硬件层
</span></span><span style=display:flex><span>└──────────────────────────┘
</span></span></code></pre></div><p><strong>“我的 Python 程序通过 PyTorch 调用 CUDA Runtime API，</strong>
<strong>CUDA Runtime 依赖 NVIDIA 驱动与硬件通信，</strong>
<strong>驱动再控制显卡完成底层计算。”</strong></p><p><strong>“CUDA 生态是一整套 GPU 加速栈：</strong>
<strong>从最底层的硬件到驱动，再到 Toolkit 和加速库，最后被深度学习框架调用。</strong>
<strong>驱动连接硬件，Toolkit 提供编译和库接口，</strong>
<strong>框架调用这些接口完成并行计算。”</strong></p><table><thead><tr><th><strong>层级</strong></th><th><strong>名称</strong></th><th><strong>作用</strong></th><th><strong>举例或说明</strong></th></tr></thead><tbody><tr><td><strong>硬件层</strong></td><td>GPU 芯片</td><td>负责并行计算（核心算力来源）</td><td>RTX 2080 Ti, RTX 3070, A100</td></tr><tr><td><strong>驱动层</strong></td><td>NVIDIA Driver</td><td>操作系统和 GPU 之间的桥梁，负责调度 GPU 资源</td><td>比如 Driver Version: 535.230.02</td></tr><tr><td><strong>运行库层</strong></td><td>CUDA Runtime / cuDNN / cuBLAS / cuFFT 等</td><td>NVIDIA 提供的各种 GPU 加速库</td><td>PyTorch 调用 cuDNN 做卷积、cuBLAS 做矩阵乘</td></tr><tr><td><strong>工具包层</strong></td><td>CUDA Toolkit</td><td>包含编译器 nvcc、头文件、开发工具</td><td>CUDA 11.3, 12.1 等</td></tr><tr><td><strong>应用层</strong></td><td>深度学习框架 / 程序</td><td>你的 Python 代码、PyTorch、TensorFlow 等</td><td>torch.cuda.is_available()</td></tr></tbody></table><ol><li><p>驱动必须 ≥ CUDA Toolkit 要求的最低版本。驱动新版可以兼容老 CUDA。</p></li><li><p>当用 conda install pytorch cudatoolkit=11.3 时，<strong>这套 CUDA runtime 是内置在 PyTorch 包里的</strong>，不会依赖系统路径</p><ul><li>所以哪怕系统没装 /usr/local/cuda，PyTorch 依然能跑。</li><li>torch.version.cuda 看到的版本即 PyTorch 编译时自带的 CUDA 版本。</li></ul></li><li><p>排查命令</p></li><li><table><thead><tr><th><strong>检查命令</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>nvidia-smi</td><td>驱动+GPU检测</td></tr><tr><td>nvcc -V</td><td>CUDA Toolkit 版本（如果系统安装了）</td></tr><tr><td>python -c &ldquo;import torch; print(torch.version.cuda)&rdquo;</td><td>PyTorch 自带 CUDA 版本</td></tr><tr><td>torch.cuda.is_available()</td><td>是否能用 GPU</td></tr></tbody></table></li></ol></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>LouFY'Log</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>